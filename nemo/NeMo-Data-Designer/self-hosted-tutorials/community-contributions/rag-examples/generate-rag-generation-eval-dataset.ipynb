{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "667b36b1",
   "metadata": {},
   "source": [
    "# üé® NeMo Data Designer: Generate Diverse RAG Evaluations\n",
    "\n",
    "> ‚ö†Ô∏è **Warning**: NeMo Data Designer is currently in Early Release and is not recommended for production use.\n",
    "\n",
    "#### üìö What you'll learn\n",
    "\n",
    "This tutorial demonstrates how to generate comprehensive evaluation datasets for Retrieval-Augmented Generation (RAG) systems, customized to your content and use cases. \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "> üëã **IMPORTANT** ‚Äì¬†Environment Setup\n",
    ">\n",
    "> - If you haven't already, follow the instructions in the [README](../../../README.md) to install the necessary dependencies.\n",
    ">\n",
    "> - You may need to restart your notebook's kernel after setting up the environment.\n",
    "> - In this notebook, we assume you have a self-hosted instance of Data Designer up and running.\n",
    ">\n",
    "> - For deployment instructions, see the [Installation Options](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/index.html#installation-options) section of the [NeMo Data Designer documentation](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc3f8fe",
   "metadata": {},
   "source": [
    "### üì¶ Import the essentials\n",
    "\n",
    "- The `data_designer` module of `nemo_microservices` exposes Data Designer's high-level SDK.\n",
    "\n",
    "- The `essentials` module provides quick access to the most commonly used objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ca1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo_microservices.data_designer.essentials import (\n",
    "    CategorySamplerParams,\n",
    "    DataDesignerConfigBuilder,\n",
    "    ExpressionColumnConfig,\n",
    "    InferenceParameters,\n",
    "    LLMJudgeColumnConfig,\n",
    "    LLMStructuredColumnConfig,\n",
    "    ModelConfig,\n",
    "    NeMoDataDesignerClient,\n",
    "    SamplerColumnConfig,\n",
    "    SamplerType,\n",
    "    Score,\n",
    "    UniformSamplerParams,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb55b35d",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Initialize the NeMo Data Designer Client\n",
    "\n",
    "- `NeMoDataDesignerClient` is responsible for submitting generation requests to the microservice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3706d9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEMO_MICROSERVICES_BASE_URL = \"http://localhost:8080\"\n",
    "\n",
    "data_designer_client = NeMoDataDesignerClient(base_url=NEMO_MICROSERVICES_BASE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6839a60",
   "metadata": {},
   "source": [
    "### üéõÔ∏è Define model configurations\n",
    "\n",
    "- Each `ModelConfig` defines a model that can be used during the generation process.\n",
    "\n",
    "- The \"model alias\" is used to reference the model in the Data Designer config (as we will see below).\n",
    "\n",
    "- The \"model provider\" is the external service that hosts the model (see [the model config docs](https://docs.nvidia.com/nemo/microservices/latest/design-synthetic-data-from-scratch-or-seeds/configure-models.html) for more details).\n",
    "\n",
    "- By default, the microservice uses [build.nvidia.com](https://build.nvidia.com/models) as the model provider.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This name is set in the microservice deployment configuration.\n",
    "MODEL_PROVIDER = \"nvidiabuild\"\n",
    "\n",
    "# The model ID is from build.nvidia.com.\n",
    "MODEL_ID = \"nvidia/nvidia-nemotron-nano-9b-v2\"\n",
    "\n",
    "# We choose this alias to be descriptive for our use case.\n",
    "MODEL_ALIAS = \"nemotron-nano-v2\"\n",
    "\n",
    "# This sets reasoning to False for the nemotron-nano-v2 model.\n",
    "SYSTEM_PROMPT = \"/no_think\"\n",
    "\n",
    "model_configs = [\n",
    "    ModelConfig(\n",
    "        alias=MODEL_ALIAS,\n",
    "        model=MODEL_ID,\n",
    "        provider=MODEL_PROVIDER,\n",
    "        inference_parameters=InferenceParameters(\n",
    "            temperature=0.6,\n",
    "            top_p=0.95,\n",
    "            max_tokens=1024,\n",
    "        ),\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5dde1a",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Initialize the Data Designer Config Builder\n",
    "\n",
    "- The Data Designer config defines the dataset schema and generation process.\n",
    "\n",
    "- The config builder provides an intuitive interface for building this configuration.\n",
    "\n",
    "- The list of model configs is provided to the builder at initialization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceafed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_builder = DataDesignerConfigBuilder(model_configs=model_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5e591",
   "metadata": {},
   "source": [
    "## üå± Loading Seed Data\n",
    "\n",
    "- We'll use the symptom-to-diagnosis dataset as our seed data. \n",
    "\n",
    "- This dataset contains patient symptoms and corresponding diagnoses which will help generate realistic medical scenarios.\n",
    "\n",
    "<br> \n",
    "\n",
    "> üå± **Why use a seed dataset?**\n",
    ">\n",
    "> - Seed datasets let you steer the generation process by providing context that is specific to your use case.\n",
    ">\n",
    "> - Seed datasets are also an excellent way to inject real-world diversity into your synthetic data.\n",
    ">\n",
    "> - During generation, prompt templates can reference any of the seed dataset fields.\n",
    "\n",
    "<br>\n",
    "\n",
    "> üí° **About datastores**\n",
    ">\n",
    "> - You can use seed datasets from _either_ the Hugging Face Hub or a locally deployed datastore.\n",
    ">\n",
    "> - By default, we use the local datastore deployed with the Data Designer microservice.\n",
    ">\n",
    "> - The datastore endpoint is specified in the deployment configuration.\n",
    "\n",
    "\n",
    "üëã **Note**: At this time, we only support using a single file as the seed. If you have multiple files you would like to use as \\\n",
    "seeds, it is recommended you consolidated these into a single file. \n",
    "<br>\n",
    "\n",
    "### ‚öôÔ∏è Document Processing\n",
    "\n",
    "Now we'll create a Document Processor class that handles loading and chunking the source documents. \n",
    "\n",
    "This class uses langchain's RecursiveCharacterTextSplitter and unstructured.io for robust document parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec3608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from unstructured.partition.auto import partition\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ec64d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    \"\"\"Handles loading and chunking source documents for RAG evaluation.\"\"\"\n",
    "\n",
    "    def __init__(self, chunk_size: int = 4192, chunk_overlap: int = 200):\n",
    "        \"\"\"Initialize with configurable chunk size and overlap.\"\"\"\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len,\n",
    "        )\n",
    "\n",
    "    def parse_document(self, uri: str) -> str:\n",
    "        \"\"\"Parse a single document from URI into raw text.\"\"\"\n",
    "        with open(uri, 'rb') as file:\n",
    "            content = file.read()\n",
    "            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "                temp_file.write(content)\n",
    "                temp_file.flush()\n",
    "                elements = partition(temp_file.name)\n",
    "\n",
    "        os.unlink(temp_file.name)\n",
    "        return \"\\n\\n\".join([str(element) for element in elements])\n",
    "\n",
    "    def process_documents(self, uris: Union[str, List[str]]) -> List[str]:\n",
    "        \"\"\"Process one or more documents into chunks for RAG evaluation.\"\"\"\n",
    "        if isinstance(uris, str):\n",
    "            uris = [uris]\n",
    "\n",
    "        all_chunks = []\n",
    "        for uri in uris:\n",
    "            text = self.parse_document(uri)\n",
    "            chunks = self.text_splitter.split_text(text)\n",
    "            all_chunks.extend(chunks)\n",
    "\n",
    "        return all_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c44785c",
   "metadata": {},
   "source": [
    "### üèóÔ∏è Data Models\n",
    "\n",
    "- Let's define Pydantic models for structured output generation. \n",
    "\n",
    "- These schemas will ensure our generated data has consistent structure and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class QAPair(BaseModel):\n",
    "    question: str = Field(\n",
    "        ..., description=\"A specific question related to the domain of the context\"\n",
    "    )\n",
    "    answer: str = Field(\n",
    "        ..., description=\"Either a context-supported answer or explanation of why the question cannot be answered\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        ..., description=\"A clear and traceable explanation of the reasoning behind the answer\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5325b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Process document chunks\n",
    "DOCUMENT_LIST = [\"./data/databricks-state-of-data-ai-report.pdf\"]\n",
    "\n",
    "processor = DocumentProcessor(chunk_size=4192, chunk_overlap=200)\n",
    "chunks = processor.process_documents(DOCUMENT_LIST)\n",
    "\n",
    "# Create a seed DataFrame with the document chunks\n",
    "seed_df = pd.DataFrame({\"context\": chunks})\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "seed_df.to_csv(\"data/document_chunks.csv\", index=False)\n",
    "\n",
    "seed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8152fe1e-6d47-435d-91c1-85a6d17b1637",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_reference = data_designer_client.upload_seed_dataset(\n",
    "    repo_id=\"data-designer-demo/rag-evaluation-dataset\",\n",
    "    dataset=seed_df,\n",
    "    datastore_settings={\"endpoint\": \"http://localhost:3000/v1/hf\"})\n",
    "\n",
    "config_builder.with_seed_dataset(dataset_reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280e2fec",
   "metadata": {},
   "source": [
    "## üé≤ Adding Categorical Columns for Controlled Diversity\n",
    "\n",
    "Now we'll add categorical columns to control the diversity of our RAG evaluation pairs. We'll define:\n",
    "\n",
    "1. **Difficulty levels**: easy, medium, hard\n",
    "\n",
    "2. **Reasoning types**: factual recall, inferential reasoning, etc.\n",
    "\n",
    "3. **Question types**: answerable vs. unanswerable (with weighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e27cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure categorical columns for controlled diversity\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"difficulty\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=[\"easy\", \"medium\", \"hard\"],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"reasoning_type\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=[\n",
    "                \"factual recall\",\n",
    "                \"inferential reasoning\",\n",
    "                \"comparative analysis\",\n",
    "                \"procedural understanding\",\n",
    "                \"cause and effect\",\n",
    "            ],\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "config_builder.add_column(\n",
    "    SamplerColumnConfig(\n",
    "        name=\"question_type\",\n",
    "        sampler_type=SamplerType.CATEGORY,\n",
    "        params=CategorySamplerParams(\n",
    "            values=[\"answerable\", \"unanswerable\"],\n",
    "            # 10:1 ratio of answerable to unanswerable questions.\n",
    "            weights=[10, 1],\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735cbbea",
   "metadata": {},
   "source": [
    "## ü¶ú Adding LLM-Structured Column for Q&A Pair Generation\n",
    "\n",
    "Now let's set up the core of our data generation: the Q&A pair column that will produce structured question-answer \\\n",
    "pairs based on our document context and control parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf44d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Q&A pair generation column\n",
    "config_builder.add_column(\n",
    "    LLMStructuredColumnConfig(\n",
    "        name=\"qa_pair\",\n",
    "        model_alias=MODEL_ALIAS,\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        prompt=(\n",
    "            \"{{context}}\\n\"\n",
    "            \"\\n\"\n",
    "            \"Generate a {{difficulty}} {{reasoning_type}} question-answer pair.\\n\"\n",
    "            \"The question should be {{question_type}} using the provided context.\\n\"\n",
    "            \"\\n\"\n",
    "            \"For answerable questions:\\n\"\n",
    "            \"- Ensure the answer is fully supported by the context\\n\"\n",
    "            \"\\n\"\n",
    "            \"For unanswerable questions:\\n\"\n",
    "            \"- Keep the question topically relevant\\n\"\n",
    "            \"- Make it clearly beyond the context's scope\\n\"\n",
    "        ),\n",
    "        output_format=QAPair,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7058d0a",
   "metadata": {},
   "source": [
    "## üîç Quality Assessment: LLM-as-a-Judge\n",
    "\n",
    "When generating our synthetic dataset, we need to determine the quality of the generated data \\\n",
    "We use the LLM-as-a-Judge strategy to do this. \n",
    "\n",
    "To do so, we need to define the rubric that the LLM should use to assess generation quality along with a prompt \n",
    "that provides relavant instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953bca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_relevance_rubric = Score(\n",
    "    name=\"Context Relevance\",\n",
    "    description=\"Evaluates how relevant the answer is to the provided context\",\n",
    "    options={\n",
    "        \"5\": \"Perfect relevance to context with no extraneous information\",\n",
    "        \"4\": \"Highly relevant with minor deviations from context\",\n",
    "        \"3\": \"Moderately relevant but includes some unrelated information\",\n",
    "        \"2\": \"Minimally relevant with significant departure from context\",\n",
    "        \"1\": \"Almost entirely irrelevant to the provided context\",\n",
    "    },\n",
    ")\n",
    "\n",
    "answer_precision_rubric = Score(\n",
    "    name=\"Answer Precision\",\n",
    "    description=\"Evaluates the accuracy and specificity of the answer\",\n",
    "    options={\n",
    "        \"5\": \"Extremely precise with exact, specific information\",\n",
    "        \"4\": \"Very precise with minor imprecisions\",\n",
    "        \"3\": \"Adequately precise but could be more specific\",\n",
    "        \"2\": \"Imprecise with vague or ambiguous information\",\n",
    "        \"1\": \"Completely imprecise or inaccurate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "answer_completeness_rubric = Score(\n",
    "    name=\"Answer Completeness\",\n",
    "    description=\"Evaluates how thoroughly the answer addresses all aspects of the question\",\n",
    "    options={\n",
    "        \"5\": \"Fully complete, addressing all aspects of the question\",\n",
    "        \"4\": \"Mostly complete with minor omissions\",\n",
    "        \"3\": \"Adequately complete but missing some details\",\n",
    "        \"2\": \"Substantially incomplete, missing important aspects\",\n",
    "        \"1\": \"Severely incomplete, barely addresses the question\",\n",
    "    },\n",
    ")\n",
    "\n",
    "hallucination_avoidance_rubric = Score(\n",
    "    name=\"Hallucination Avoidance\",\n",
    "    description=\"Evaluates the absence of made-up or incorrect information\",\n",
    "    options={\n",
    "        \"5\": \"No hallucinations, all information is factual and verifiable\",\n",
    "        \"4\": \"Minimal hallucinations that don't impact the core answer\",\n",
    "        \"3\": \"Some hallucinations that partially affect the answer quality\",\n",
    "        \"2\": \"Significant hallucinations that undermine the answer\",\n",
    "        \"1\": \"Severe hallucinations making the answer entirely unreliable\",\n",
    "    },\n",
    ")\n",
    "\n",
    "EVAL_METRICS_PROMPT_TEMPLATE = (\n",
    "    \"You are an expert evaluator of question-answer pairs. Analyze the following Q&A pair and evaluate it objectively.\\n\\n\"\n",
    "    \"For this {{difficulty}} {{reasoning_type}} Q&A pair:\\n\"\n",
    "    \"{{qa_pair}}\\n\\n\"\n",
    "    \"Take a deep breath and carefully evaluate each criterion based on the provided rubrics, considering the \"\n",
    "    \"difficulty level and reasoning type indicated.\"\n",
    ")\n",
    "\n",
    "config_builder.add_column(\n",
    "    LLMJudgeColumnConfig(\n",
    "        name=\"eval_metrics\",\n",
    "        model_alias=MODEL_ALIAS,\n",
    "        system_prompt=SYSTEM_PROMPT,\n",
    "        prompt=EVAL_METRICS_PROMPT_TEMPLATE,\n",
    "        scores=[\n",
    "            context_relevance_rubric,\n",
    "            answer_precision_rubric,\n",
    "            answer_completeness_rubric,\n",
    "            hallucination_avoidance_rubric,\n",
    "        ],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff88d0",
   "metadata": {},
   "source": [
    "### üîÅ Iteration is key ‚Äì¬†preview the dataset!\n",
    "\n",
    "1. Use the `preview` method to generate a sample of records quickly.\n",
    "\n",
    "2. Inspect the results for quality and format issues.\n",
    "\n",
    "3. Adjust column configurations, prompts, or parameters as needed.\n",
    "\n",
    "4. Re-run the preview until satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efdf43d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Preview a few records\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m preview = \u001b[43mdata_designer_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_builder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/nemo_microservices/data_designer/client/data_designer_client.py:140\u001b[39m, in \u001b[36mNeMoDataDesignerClient.preview\u001b[39m\u001b[34m(self, config_builder, num_records, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate a set of preview records based on your current Data Designer configuration.\u001b[39;00m\n\u001b[32m    127\u001b[39m \n\u001b[32m    128\u001b[39m \u001b[33;03mThis method is meant for fast iteration on your Data Designer configuration.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    137\u001b[39m \u001b[33;03m    An object containing the preview dataset and tools for inspecting the results.\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_capture_preview_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_builder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig_builder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_records\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    142\u001b[39m     handle_api_exceptions(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/nemo_microservices/data_designer/client/data_designer_client.py:229\u001b[39m, in \u001b[36mNeMoDataDesignerClient._capture_preview_result\u001b[39m\u001b[34m(self, config_builder, num_records, timeout)\u001b[39m\n\u001b[32m    226\u001b[39m timeout = _resolve_timeout(timeout, config_builder, num_records)\n\u001b[32m    228\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33müöÄ Starting preview generation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_designer_resource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_records\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage_type\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mMessageType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHEARTBEAT\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mcontinue\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/nemo_microservices/_decoders/jsonl.py:81\u001b[39m, in \u001b[36mJSONLDecoder.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[_T]:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/nemo_microservices/_decoders/jsonl.py:60\u001b[39m, in \u001b[36mJSONLDecoder.__decode__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__decode__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[_T]:\n\u001b[32m     59\u001b[39m     buf = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeepends\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/httpx/_models.py:897\u001b[39m, in \u001b[36mResponse.iter_bytes\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    895\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/httpx/_models.py:951\u001b[39m, in \u001b[36mResponse.iter_raw\u001b[39m\u001b[34m(self, chunk_size)\u001b[39m\n\u001b[32m    948\u001b[39m chunker = ByteChunker(chunk_size=chunk_size)\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=\u001b[38;5;28mself\u001b[39m._request):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_num_bytes_downloaded\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_stream_bytes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/httpx/_client.py:153\u001b[39m, in \u001b[36mBoundSyncStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/httpx/_transports/default.py:127\u001b[39m, in \u001b[36mResponseStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpcore_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:407\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:403\u001b[39m, in \u001b[36mPoolByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> typing.Iterator[\u001b[38;5;28mbytes\u001b[39m]:\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:342\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ShieldCancellation():\n\u001b[32m    341\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n\u001b[32m--> \u001b[39m\u001b[32m342\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:334\u001b[39m, in \u001b[36mHTTP11ConnectionByteStream.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    333\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mreceive_response_body\u001b[39m\u001b[33m\"\u001b[39m, logger, \u001b[38;5;28mself\u001b[39m._request, kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    337\u001b[39m     \u001b[38;5;66;03m# If we get an exception while streaming the response,\u001b[39;00m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# we want to close the response (and possibly the connection)\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# before raising that exception.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:203\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_body\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    200\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Data):\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m(event.data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/projects/NeMo_SDG/sdg_venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Preview a few records\n",
    "preview = data_designer_client.preview(config_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da20a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More previews\n",
    "preview.display_sample_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfd025b",
   "metadata": {},
   "source": [
    "### üìä Analyze the generated data\n",
    "\n",
    "- Data Designer automatically generates a basic statistical analysis of the generated data.\n",
    "\n",
    "- This analysis is available via the `analysis` property of generation result objects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79185c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the analysis as a table.\n",
    "preview.analysis.to_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6fc118",
   "metadata": {},
   "source": [
    "### üÜô Scale up!\n",
    "\n",
    "- Happy with your preview data?\n",
    "\n",
    "- Use the `create` method to submit larger Data Designer generation jobs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5568d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_results = data_designer_client.create(config_builder, num_records=20)\n",
    "\n",
    "# This will block until the job is complete.\n",
    "job_results.wait_until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa51230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generated dataset as a pandas DataFrame.\n",
    "dataset = job_results.load_dataset()\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9fd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the analysis results into memory.\n",
    "analysis = job_results.load_analysis()\n",
    "\n",
    "analysis.to_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUTORIAL_OUTPUT_PATH = \"data-designer-tutorial-output\"\n",
    "\n",
    "# Download the job artifacts and save them to disk.\n",
    "job_results.download_artifacts(\n",
    "    output_path=TUTORIAL_OUTPUT_PATH,\n",
    "    artifacts_folder_name=\"artifacts-community-contributions-rag-examples-generate-rag-generation-eval-dataset\",\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "sdg_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
